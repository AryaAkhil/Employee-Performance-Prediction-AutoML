{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"AutoKeras_Employee_Performance_Prediction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"x3YZdAoQO5eF"},"source":["# Employee performance prediction using Auto ML\n","\n","This python script aims to predict employee performance flag using 1731 data points originally provided."]},{"cell_type":"markdown","metadata":{"id":"9T3cYEAVYhVa"},"source":["## Install relevant packages\n","\n","If users are using google colab, except autokeras rest of the packages mentioned in the \"Data Import\" section below are installed by default. In your local machine you might have to install these packages as per your prior usage of python - \n","1. pandas\n","2. numpy\n","3. os\n","4. tensorflow\n","5. seaborn\n","6. imblearn\n","7. metrics\n","8. matlplotlib\n","10. autokeras"]},{"cell_type":"code","metadata":{"id":"6LejkSOFRGpS"},"source":["#!pip install autokeras\n","#!pip install tensorflow-addons"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tb2MpnAxQIks"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"gNi1IH-dPujB"},"source":["from google.colab import drive\n","import pandas as pd\n","import os\n","from scipy import mean\n","import numpy as np\n","import tensorflow as tf\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, fbeta_score, cohen_kappa_score, roc_auc_score, confusion_matrix, precision_score,make_scorer\n","from imblearn.over_sampling import BorderlineSMOTE\n","from autokeras import StructuredDataClassifier\n","import tensorflow_addons as tfa\n","from kerastuner import Objective\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mLM_4yadRf2w"},"source":["## Set working directory\n","\n","If you are using google colab, place the csv input file in your google directory and the next 3 lines of code should do the magic. Else,if you are using your own local machine, coment the first line of code in below cell and just replace the root_dir below with your local working directory to set."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufDEQFMHRSkH","executionInfo":{"status":"ok","timestamp":1621669313595,"user_tz":-330,"elapsed":1401,"user":{"displayName":"ARYA AKHIL _","photoUrl":"","userId":"03888002519836551564"}},"outputId":"ce62fadf-02ad-498c-e2e0-3474caed8435"},"source":["drive.mount('/content/gdrive', force_remount=True)\n","root_dir = \"/content/gdrive/MyDrive/Colab_Notebooks/AutoML_development\"\n","os.chdir(root_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"39gFjC-qQxMT"},"source":["**Note to users: Make sure to create a new folder in your working directory named \"Autokeras_Saved_Models\".**"]},{"cell_type":"markdown","metadata":{"id":"P_pkwS7-Pq4G"},"source":["## Data Import"]},{"cell_type":"code","metadata":{"id":"vg9me5GORgEC"},"source":["df = pd.read_csv(\"ML_input.csv\")\n","df.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ulZsp9GPkrff"},"source":["## Data pre-processing"]},{"cell_type":"markdown","metadata":{"id":"1VmaeScFVnS8"},"source":["\n","Data cleaning has already been taken care. Given the nature of the problem, dropping irrelevant columns \n","'Person_ID','Name','Type_ID','Service','Group','Group_ID','Score'"]},{"cell_type":"code","metadata":{"id":"TH33066tVGIp"},"source":["df_model = df.drop(columns = ['Person_ID','Name','Type_ID','Service','Group','Group_ID','Score'])\n","df_model.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eYeSF8cSgYmi"},"source":["## Data preparation"]},{"cell_type":"code","metadata":{"id":"b-lX-Fe-g2cl"},"source":["# prepare train data for training\n","def prepare_train_data(df_model,p):\n","  \n","  # define train and test set in each iteration of training\n","  train = df_model[df_model['Period']<=p]\n","\n","  # split data into train and test as per each iteration\n","  X_train = train.iloc[:,2:]\n","  y_train = train.iloc[:,1]\n","\n","  return X_train,y_train\n","\n","# prepare test data for evaluation\n","def prepare_test_data(df_model,p):\n","  \n","  # define test set in each iteration of evaluation\n","  test = df_model[df_model['Period']==p]\n","\n","  # split data into train and test as per each iteration\n","  X_test = test.iloc[:,2:]\n","  y_test = test.iloc[:,1]\n","\n","  return X_test,y_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WwOxHgTZm30r"},"source":["## Borderline SMOTEing\n","\n","Documentation - https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html\n","\n","Reference article - https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n","\n","\n","**Note to users: \n","Users of this notebook don't need to run the below code cell. This cell was used during model training. Best model has been shared as \".h5\" file that can be loaded and made to predict on desired period in \"User-section\" of the notebook later.**"]},{"cell_type":"code","metadata":{"id":"ZqZ6YFtlm5mm"},"source":["def borderline_sample(X_train,y_train):\n","  oversample = BorderlineSMOTE()\n","  X_train, y_train = oversample.fit_resample(X_train, y_train)\n","\n","  return X_train,y_train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BDJoaiUH2KLF"},"source":["## Model Definition\n","\n","Documentation for autokeras - https://autokeras.com/tutorial/structured_data_classification/\n","\n","**Note to users: \n","Users of this notebook don't need to run the below code cell. This cell was used during model training. Best model has been shared as \".h5\" file that can be loaded and made to predict on desired period in \"User-section\" of the notebook later.**"]},{"cell_type":"code","metadata":{"id":"AouIqkxOwqY9"},"source":["# Autokeras\n","def auto_keras(X_train,y_train):\n","\n","  # build model\n","  model = StructuredDataClassifier(max_trials=20,\n","                                  overwrite=True,\n","                                  objective=Objective('val_true_positives', direction='max'),\n","                                  metrics=[\"TruePositives\"]\n","                                  )\n","\n","  # fit model\n","  model.fit(x=X_train,y=y_train)\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ah5MAxlez28E"},"source":["## Model Run\n","\n","**Note to users: \n","Users of this notebook don't need to run the below code cell. This cell was used during model training. Best model has been shared as \".h5\" file that can be loaded and made to predict on desired period in \"User-section\" of the notebook later.**"]},{"cell_type":"code","metadata":{"id":"k4IJmn5wyw2F"},"source":["# Shift data and train model. As data is time sensitive, need to find the best model\n","for p in range(1,25):\n","  \n","  # prepare data for current iteration\n","  X_train,y_train = prepare_train_data(df_model,p)\n","\n","  # borderline SMOTE\n","  X_train, y_train = borderline_sample(X_train,y_train)\n","  \n","  # fit model\n","  model = auto_keras(X_train,y_train)\n","\n","  # get the best performing model\n","  exprt = model.export_model()\n","\n","  # print summary\n","  #exprt.summary()\n","\n","  # save the best performing model to file\n","  exprt.save('Autokeras_Saved_Models/Model trained upto period ' + str(p) + '.h5')\n","\n","  # print training iteration\n","  print('Trained period upto= ',p)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yf3h7jX5uPE1"},"source":["## Model Evaluation\n","\n","**Note to users: \n","Users of this notebook don't need to run the below code cell. This cell was used during model training. Best model has been shared as \".h5\" file that can be loaded and made to predict on desired period in \"User-section\" of the notebook later.**"]},{"cell_type":"code","metadata":{"id":"wSD7jDj-pfsd"},"source":["# define a mean precision score dictionary at model level to evaluate best model\n","mean_prec_dict = {}\n","\n","# load all models one by one\n","for mdl in range(1,24):\n","\n","  # load model\n","  model = tf.keras.models.load_model('Autokeras_Saved_Models/Model trained upto period ' + str(mdl) + '.h5')\n","\n","  # forward chaining evaluation\n","  for p in range(mdl+1,26):\n","\n","      # define primary evaluation dictionary\n","      prec_dict = {}\n","\n","      # prepare test data for each iteration\n","      X_test,y_test = prepare_test_data(df_model,p)\n","\n","      # predict on test - this predicts probabilities\n","      y_hat = model.predict(X_test)\n","\n","      # convert probabilities to classes using threshold = 0.5\n","      y_hat = np.where(y_hat > 0.5, 1, 0)\n","\n","      # f beta score, beta = 0.5 to increase weightage to precision - want to reduce false +ve\n","      prec = precision_score(y_test, y_hat)\n","\n","      # store scores in a dictionary\n","      prec_dict['mdl=' + str(mdl) + '_test_p=' + str(p)] = prec\n","      print(prec_dict)\n","\n","  # mean score of precision for a model across 24 period of evaluation\n","  mean_prec_dict['Model=' + str(mdl)] = list(map(lambda x: mean(prec_dict[x]), prec_dict))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zuAAsp02ZqNL"},"source":["## User section - load best model and predict"]},{"cell_type":"markdown","metadata":{"id":"VOkJi1HYX3pi"},"source":["After running the above two cells of code we obtain some insights on the performance of different models over different test sets. Based on the observations on model no. and mean precision score, model-6 had the highest mean precision score of all models, hence selecting it to be the final model.\n","User can run the below cell to load model-6 from working directory and predict on any period they like. Model-6 is shared as separate \".h5\" file. Make sure it is present in your working directory.\n","\n","Model-6 is trained using first 6 periods only, yet it yielded highest mean precision score. This indicates a seasonal behaviour in data and that data is indeed time sensitive."]},{"cell_type":"code","metadata":{"id":"0FKqPk9NSBFV"},"source":["# load model\n","m = 6\n","model = tf.keras.models.load_model('Autokeras_Saved_Models/Model trained upto period ' + str(m) + '.h5')\n","\n","# prepare test for period 25 and onwards - just change p to whichever period you want to predict. Make sure to not disturb the format of ML_Input.csv file.\n","p = 7\n","X_test,y_test = prepare_test_data(df_model,p)\n","\n","# predict on test - this predicts probabilities\n","y_hat = model.predict(X_test)\n","\n","# convert probabilities to classes using threshold = 0.5. User can play around with this threshold of 0.5 to increase true positives.\n","y_hat = np.where(y_hat > 0.5, 1, 0)\n","\n","# plot confusion matrix\n","cm=confusion_matrix(y_test,y_hat)\n","ax= plt.subplot()\n","sns.heatmap(cm, annot=True, fmt='g', ax=ax)\n","ax.set_xlabel('Predicted labels')\n","ax.set_ylabel('True labels')\n","ax.set_title('Confusion Matrix')\n","ax.xaxis.set_ticklabels(['Low P','High P'])\n","ax.yaxis.set_ticklabels(['Low P','High P'])\n","\n","# precision score\n","prec = precision_score(y_test, y_hat)\n","print(\"Precision: \", round(prec*100,2), \"%\")\n","\n","# accuracy\n","acc = accuracy_score(y_test, y_hat)\n","print(\"Accuracy: \", round(acc*100,2), \"%\")\n","\n","# cohen kappa score\n","kappa = cohen_kappa_score(y_test, y_hat)\n","print(\"Kappa: \", round(kappa*100,2), \"%\")\n","\n","# f beta score, beta = 0.5 to increase weightage to precision - want to reduce false +ve\n","f_beta = fbeta_score(y_test, y_hat,beta=0.5)\n","print(\"F-0.5: \", round(f_beta*100,2), \"%\")\n","\n","# roc score\n","auc = roc_auc_score(y_test, y_hat) \n","print(\"AUC: \", round(auc*100,2), \"%\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"95vA5vD5o9cq"},"source":["# END"]}]}